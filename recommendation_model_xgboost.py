# -*- coding: utf-8 -*-
"""Recommendation Model_XGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hwpzXeC5BXZdujNZEMnltqDz1h2Tf4_Z
"""

# Link the google drive in it
from google.colab import drive
drive.mount('/content/drive')

#from xgboost import XGBClassifier
#import numpy as np
#import pandas as pd
#import sklearn
#from sklearn.multiclass import OneVsRestClassifier

import pandas as pd
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
from pathlib import Path
from pprint import pprint

# Direct to the file location in the Google Drive
datapath = Path("/content/drive/MyDrive/0_2024_Mine_PreProject/2025_VimMatch_Clients Recommendation AI Agent/Vimmax/Recommendation System_XGBoost_info")
# Load CSVs
clients = pd.read_csv(datapath / "sample_clients.csv")
products = pd.read_csv(datapath / "sample_products.csv")
interactions = pd.read_csv(datapath / "sample_interactions.csv")

# (failed) Create a folder in the root directory
#!mkdir -p "/content/drive/MyDrive/0_2024_Mine_PreProject/2025_VimMatch_Clients Recommendation AI Agent/Vimmax/Recommendation System_XGBoost_info/Test") #"/content/drive/My Drive/My Folder"

"""
# Load your CSV files
clients = pd.read_csv("sample_clients.csv")
products = pd.read_csv("sample_products.csv")
interactions = pd.read_csv("sample_interactions.csv")
"""
# Merge into one dataset
df = interactions.merge(clients, on="client_id").merge(products, on="product_id")

# Label encode outcome
df["label"] = df["outcome"].map({"Partnered": 1, "Rejected": 0})

# Select columns to use
categorical = [
    "platform", "region_x", "content_type", "price_tier",
    "price_range", "aesthetic", "target_user", "region_y"
]
numeric = ["audience_size", "avg_engagement"]

# Encode categorical features
encoder = OneHotEncoder(sparse_output=False)
encoded = encoder.fit_transform(df[categorical])
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical))

# Combine into final training dataset
X = pd.concat([df[numeric].reset_index(drop=True), encoded_df], axis=1)
y = df["label"]

# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train XGBoost model
model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")
model.fit(X_train, y_train)

# Evaluate model
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Predict scores on full dataset (for exploration/recommendation)
df["score"] = model.predict_proba(X)[:, 1]
df.to_csv("match_recommendations.csv", index=False)
print("âœ… Saved: match_recommendations.csv")

"""## Below is the old script, try it for learning"""

# Direct to the file location in the Google Drive
datapath = Path("/content/drive/MyDrive/0_2024_Mine_PreProject/2025_VimMatch_Clients Recommendation AI Agent/Vimmax/Recommendation System_XGBoost_info")
# Load CSVs
clients = pd.read_csv(datapath / "sample_clients.csv")
products = pd.read_csv(datapath / "sample_products.csv")
interactions = pd.read_csv(datapath / "sample_interactions.csv")

# Merge all
df = interactions.merge(clients, on="client_id").merge(products, on="product_id")

#print(df)

# Label encode outcome
df["label"] = df["outcome"].map({"Partnered": 1, "Rejected": 0})
pprint(df)
df.shape

# Feature selection
categorical = [
    "platform", "region_x", "content_type", "price_tier",
    "price_range", "aesthetic", "target_user", "region_y"
]
numeric = ["audience_size", "avg_engagement"]

print(type(categorical))
print(type(numeric))

# Transform the feature into lables

# One-hot encode categorical
encoder = OneHotEncoder(cFalse)
encoded = encoder.fit_transform(df[categorical])
#print(encoded)
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical))

# Combine features
X = pd.concat([df[numeric].reset_index(drop=True), encoded_df], axis=1)
y = df["label"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train XGBoost
model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

# Merge all
df = interactions.merge(clients, on="client_id").merge(products, on="product_id")

# Label encode outcome
df["label"] = df["outcome"].map({"Partnered": 1, "Rejected": 0})

# Feature selection
categorical = [
    "platform", "region_x", "content_type", "price_tier",
    "price_range", "aesthetic", "target_user", "region_y"
]
numeric = ["audience_size", "avg_engagement"]

# One-hot encode categorical
encoder = OneHotEncoder(sparse_output=False)
encoded = encoder.fit_transform(df[categorical])
encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(categorical))

# Combine features
X = pd.concat([df[numeric].reset_index(drop=True), encoded_df], axis=1)
y = df["label"]

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train XGBoost
model = XGBClassifier(use_label_encoder=False, eval_metric="logloss")
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))

